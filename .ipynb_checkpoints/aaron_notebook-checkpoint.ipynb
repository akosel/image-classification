{
 "metadata": {
  "name": "",
  "signature": "sha256:1bde76eb5957f22a690d90cda767ed0f30c603c2d10a7e018826e7e6e388009b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import sets\n",
      "from PIL import Imag\n",
      "\n",
      "from sklearn.decomposition import RandomizedPCA\n",
      "from sklearn.neighbors import KNeighborsClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# setup a standard image size; this will distort some images but will get everything into the same shape\n",
      "# functions based off of yhat's tutorial http://blog.yhathq.com/posts/image-classification-in-Python.html\n",
      "def img_to_matrix(filename, useHsv=False, imageSize=(200, 200)):\n",
      "    \"\"\"\n",
      "    takes a filename and turns it into a numpy array of RGB pixels\n",
      "    \"\"\"\n",
      "    img = Image.open(filename)\n",
      "    img = img.resize(imageSize)\n",
      "    if useHsv:\n",
      "        rgb_img_data = list(img.getdata())\n",
      "        hsv_img_data = list(img.convert('HSV').getdata())\n",
      "        img = [rgb_img_data[idx] + hsv_img_data[idx] for idx in xrange(len(rgb_img_data))]\n",
      "    else:\n",
      "        img = list(img.getdata())\n",
      "    img = map(list, img)\n",
      "    img = np.array(img)\n",
      "    return img\n",
      "\n",
      "def flatten_image(img):\n",
      "    \"\"\"\n",
      "    takes in an (m, n) numpy array and flattens it \n",
      "    into an array of shape (1, m * n)\n",
      "    \"\"\"\n",
      "    s = img.shape[0] * img.shape[1]\n",
      "    img_wide = img.reshape(1, s)\n",
      "    return img_wide[0]\n",
      "\n",
      "# image size, number of classes, number of components, number of k neighbors, isHsl\n",
      "def printPrediction(imageSize, useHsv, numberOfClasses, numberOfComponents=5, numberOfKNeighbors=10):\n",
      "    \"\"\"\n",
      "    takes a number of arguments and walks through the pipeline.\n",
      "    does not return anything, but does write a file with the\n",
      "    results in it.\n",
      "    looks at existing files first to see if a particular prediction\n",
      "    has already been run.\n",
      "    \"\"\"\n",
      "    if cacheLookup(imageSize, useHsv, numberOfClasses, numberOfComponents, numberOfKNeighbors):\n",
      "        return 'Found in cache'\n",
      "    else:\n",
      "        print 'Not found in cache, building results'\n",
      "        \n",
      "    images = [os.path.join('img', f) for f in os.listdir('img') if f[0] != '.']\n",
      "    \n",
      "    # XXX need to work out the sorting here\n",
      "    labels = [getLabel(f) for f in images]\n",
      "    \n",
      "    labelList = sorted(list(sets.Set(labels)))\n",
      "    cutoffClass = labelList[numberOfClasses]\n",
      "    cutoffIdx = labels.index(cutoffClass)\n",
      "\n",
      "    images, labels = images[:cutoffIdx], labels[:cutoffIdx]\n",
      "    labelList = sorted(list(sets.Set(labels)))\n",
      "    data = []\n",
      "    for image in images:\n",
      "        img = img_to_matrix(image, useHsv=useHsv, imageSize=imageSize)\n",
      "        img = flatten_image(img)\n",
      "        data.append(img)\n",
      "\n",
      "    data = np.array(data)\n",
      "    \n",
      "    is_train = np.random.uniform(0, 1, len(data)) <= 0.8\n",
      "    y = np.array(labels)\n",
      "\n",
      "    train_x, train_y = data[is_train], y[is_train]\n",
      "    test_x, test_y = data[is_train==False], y[is_train==False]\n",
      "    \n",
      "    pca = RandomizedPCA(n_components = numberOfComponents)\n",
      "    X = pca.fit_transform(data)\n",
      "    \n",
      "    knn = KNeighborsClassifier(n_neighbors = numberOfKNeighbors)\n",
      "    knn.fit(train_x, train_y)\n",
      "\n",
      "    ct = pd.crosstab(test_y, knn.predict(test_x), rownames=['Actual'], colnames=['Predicted'])\n",
      "    filename = str(imageSize[0]) + '_' + str(imageSize[1]) + '_nco' + str(numberOfComponents) + '_ncl' + str(numberOfClasses) + '_nkn' + str(numberOfKNeighbors) + '.csv'\n",
      "    ct.to_csv(os.path.join('results', filename))\n",
      "    print ct\n",
      "    \n",
      "def cacheLookup(imageSize, useHsv, numberOfClasses, numberOfComponents, numberOfKNeighbors):\n",
      "    \"\"\"\n",
      "    using the file naming convention defined in printPrediction,\n",
      "    checks to see if the same classification has already run.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        filename = str(imageSize[0]) + '_' + str(imageSize[1]) + '_nco' + str(numberOfComponents) + '_ncl' + str(numberOfClasses) + '_nkn' + str(numberOfKNeighbors) + '.csv'\n",
      "        ct = pd.read_csv(os.path.join('results', filename))\n",
      "        print ct\n",
      "        return True\n",
      "    except:\n",
      "        return False\n",
      "    \n",
      "# helper functions\n",
      "def getLabel(path):\n",
      "    \"\"\"\n",
      "    small helper that takes a given filename, and returns\n",
      "    the label, assuming the file is named like so:\n",
      "    cornmarket_000079.jpg will return cornmarket\n",
      "    \"\"\"\n",
      "    return path[path.index('/') + 1:path.rindex('_')]\n",
      "\n",
      "def labelToInt(label):\n",
      "    return labelList.index(label)\n",
      "\n",
      "def intToLabel(idx):\n",
      "    return labelList[idx]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "printPrediction((200, 200), True, 2, 5, 10)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      Actual  all_souls  ashmolean\n",
        "0  all_souls         19         13\n",
        "1  ashmolean         13         37\n",
        "      Actual  all_souls  ashmolean\n",
        "0  all_souls         12         16\n",
        "1  ashmolean          7         30\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 180,
       "text": [
        "'Found in cache'"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cacheLookup((200, 200), False, 5, 5, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "          Actual  all_souls  ashmolean  bodleian  christ_church\n",
        "0      all_souls          7          7         2             14\n",
        "1      ashmolean          0         22         4             12\n",
        "2        balliol          1          9         1             16\n",
        "3       bodleian          3          7         7             32\n",
        "4  christ_church          2         26         7             68\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 165,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 165
    }
   ],
   "metadata": {}
  }
 ]
}